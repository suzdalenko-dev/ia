# üìö Calendario IA 12 Meses + Predicci√≥n de Compras (Versi√≥n Detallada)

Este plan est√° **explicado paso a paso**, con *qu√© es*, *para qu√© sirve*, *c√≥mo estudiarlo*, *pitfalls*, *entregables* y *recursos* en cada etapa.  
Perfil objetivo: dev full‚Äëstack (**HTML/JS/PHP/Java/Python/Kotlin/Android/SQL/SQLite/Laravel/Symfony/Django/Vue**).

> **Resultado**: portafolio de 10+ proyectos, APIs listas para producci√≥n, y un **motor de compras** (forecast ‚Üí cantidad a pedir) con m√©tricas de negocio.

---

## C√≥mo usar este plan
- **Estructura de aprendizaje por tema**: *Qu√© es ‚Üí Para qu√© sirve ‚Üí C√≥mo estudiarlo (pasos) ‚Üí Pitfalls ‚Üí Entregables ‚Üí Recursos.*  
- **Tiempo**: 6‚Äì10 h/semana. Cada semana tiene objetivos concretos.  
- **Repositorio**: usa esta estructura base:
```
project/
  data/            # raw/processed/interim/external
  notebooks/
  src/
  models/
  api/
  reports/
  docker/
  .env.example
  requirements.txt / pyproject.toml
  Makefile
```
- **Workflow**: (1) Leer, (2) Reproducir, (3) Re-implementar sin mirar, (4) Aplicar a tus datos, (5) Documentar.

---

## Mes 1 ‚Äî Fundamentos pr√°cticos

### Semana 1 ‚Äî Python cient√≠fico y entorno
**Qu√© es**: base de Python para datos (entornos, paquetes, tipado, testing).  
**Para qu√© sirve**: reproducibilidad, calidad, facilidad para desplegar.  
**C√≥mo estudiarlo**:
1) Crea entorno (`venv`/`conda`/`poetry`) y *Makefile* con tareas (`make setup`, `make test`).  
2) Domina `numpy` (arrays, broadcasting) y `pandas` (DataFrames, `merge`, `groupby`, `pivot`).  
3) Visualiza con `matplotlib` (l√≠neas, barras, boxplots) y `plotly` (opcional).
**Pitfalls**: mezclar versiones de Python; `SettingWithCopy` en pandas; no fijar semillas.  
**Entregables**: notebook con 10 operaciones `pandas` t√≠picas + script `src/etl.py`.  
**Recursos**: Documentaci√≥n oficial de Python, Numpy y Pandas; ‚ÄúEffective Pandas‚Äù (Tom Augspurger).

### Semana 2 ‚Äî √Ålgebra/Estad√≠stica aplicada
**Qu√© es**: conceptos m√≠nimos (vectores, matrices, derivadas, media, varianza, percentiles).  
**Para qu√© sirve**: entender *loss/gradientes* y c√≥mo evaluar modelos.  
**C√≥mo estudiarlo**: implementa a mano media/varianza; calcula z‚Äëscores; deriva MSE respecto a w.  
**Pitfalls**: confundir poblaci√≥n vs muestra (usa `ddof=1` para std muestral).  
**Entregables**: notebook con medidas de tendencia/dispersion + gr√°fico de distribuci√≥n.  
**Recursos**: ‚ÄúMathematics for ML‚Äù (cap√≠tulos intro); Khan Academy (probabilidad).

### Semana 3 ‚Äî EDA y limpieza
**Qu√© es**: *Exploratory Data Analysis* para conocer datos antes de modelar.  
**Para qu√© sirve**: descubrir *outliers*, *missing*, *leakage*, estacionalidad.  
**C√≥mo**: perfiles (`describe`, `info`), IQR y Z‚Äëscore para outliers, imputaci√≥n (media/mediana/forward‚Äëfill).  
**Pitfalls**: imputar objetivos; eliminar filas sin entender el negocio.  
**Entregables**: reporte EDA (notebook) + checklist de calidad de datos.  
**Recursos**: ‚ÄúPractical Statistics for Data Scientists‚Äù, Pandas Profiling (ydata-profiling).

### Semana 4 ‚Äî Dashboard inicial
**Qu√© es**: panel con KPIs y gr√°ficos.  
**Para qu√© sirve**: comunicar hallazgos y validar con stakeholders.  
**C√≥mo**: Streamlit con tres vistas (resumen, tendencias, detalle por categor√≠a).  
**Entregables**: app Streamlit + README con decisiones.  
**Recursos**: docs de Streamlit; ‚ÄúStorytelling with Data‚Äù (Cole Nussbaumer).

---

## Mes 2 ‚Äî ML cl√°sico I

### Semana 1 ‚Äî Tareas y *pipelines*
**Qu√© es**: ML supervisado (regresi√≥n/clasificaci√≥n) y no supervisado (clustering). *Pipeline* = preprocesamiento + modelo.  
**Para qu√©**: evitar *data leakage* y tener procesos repetibles.  
**C√≥mo**: `sklearn.Pipeline` con escalado (`StandardScaler`) + modelo; *split* `train/test` temporal si hay fechas.  
**Pitfalls**: escalar con todo el dataset; barajar datos temporales.  
**Entregables**: notebook con pipeline y validaci√≥n inicial.  
**Recursos**: docs scikit‚Äëlearn (User Guide ‚Üí Pipeline & Model Evaluation).

### Semana 2 ‚Äî Regresi√≥n
**Qu√© es**: predecir valores num√©ricos (lineal, ridge, lasso).  
**Para qu√©**: precios, tiempos, demanda agregada.  
**C√≥mo**: eval√∫a con **MAE**, **RMSE**, **MAPE**; compara L1 vs L2; curvas de aprendizaje.  
**Pitfalls**: multicolinealidad; usar R¬≤ en series temporales puras.  
**Entregables**: benchmark de 3 modelos + an√°lisis de residuos.  
**Recursos**: G√©ron ‚ÄúHands‚ÄëOn ML‚Äù, cap√≠tulos de regresi√≥n.

### Semana 3 ‚Äî Clasificaci√≥n
**Qu√© es**: predecir clases (log√≠stica, √°rboles, random forest).  
**Para qu√©**: fraude, churn, spam.  
**C√≥mo**: m√©tricas **Precision/Recall/F1**, **ROC‚ÄëAUC** (clases balanceadas) y **PR‚ÄëAUC** (desbalance).  
**Pitfalls**: accuracy enga√±oso; *threshold tuning* ignorado.  
**Entregables**: matriz de confusi√≥n + *report* con umbral √≥ptimo.  
**Recursos**: ‚ÄúIntroduction to Statistical Learning‚Äù (ISL).

### Semana 4 ‚Äî Clustering y reducci√≥n
**Qu√© es**: **k‚Äëmeans**, **DBSCAN**; **PCA** para reducir dimensiones.  
**Para qu√©**: segmentar clientes, detectar outliers, acelerar modelos.  
**C√≥mo**: elige k con codo/silhouette; PCA: varianza explicada.  
**Pitfalls**: escalar antes de k‚Äëmeans y PCA; interpretar PCA como ‚Äúfeatures reales‚Äù.  
**Entregables**: segmentos con perfiles + visualizaci√≥n 2D PCA.  
**Recursos**: User Guide scikit‚Äëlearn (Clustering, Decomposition).

---

## Mes 3 ‚Äî ML cl√°sico II + API

### Semana 1 ‚Äî Feature Engineering
**Qu√© es**: crear variables √∫tiles (lag, medias m√≥viles, *one‚Äëhot*, *target encoding*).  
**Para qu√©**: mejorar se√±al del modelo.  
**C√≥mo**: *lags* y *rolling* con `pandas`; `CategoricalEncoder`/`TargetEncoder`.  
**Pitfalls**: fuga por *target encoding* mal validado; usar *future info*.  
**Entregables**: script `src/features.py` + pruebas unitarias.  

### Semana 2 ‚Äî Validaci√≥n e *Hyper‚Äëtuning*
**Qu√© es**: **K‚ÄëFold**, **TimeSeriesSplit**; **Grid/Random/Bayes Search**.  
**Para qu√©**: estimar performance honesta y elegir hiperpar√°metros.  
**C√≥mo**: `TimeSeriesSplit(n_splits=5)`; `RandomizedSearchCV`.  
**Pitfalls**: mezclar validaci√≥n aleatoria con series temporales.  
**Entregables**: informe de *tuning* + importancias (Permutation/SHAP).  

### Semana 3 ‚Äî Proyecto: Spam
**Qu√© es**: clasificador textual con TF‚ÄëIDF + LogReg/LinearSVM.  
**Para qu√©**: detectar spam/soporte automatizado.  
**C√≥mo**: `TfidfVectorizer` (word/char n‚Äëgrams), normaliza y regulariza.  
**Entregables**: notebook + `src/train.py` + `models/`.  

### Semana 4 ‚Äî API y Docker
**Qu√© es**: servir modelos v√≠a **FastAPI/Django REST**; empaquetar con Docker.  
**Para qu√©**: consumo desde Vue/Android/otros servicios.  
**C√≥mo**: endpoint `/predict`, validaci√≥n con Pydantic, healthcheck; `Dockerfile` multi‚Äëstage.  
**Pitfalls**: no fijar versiones; falta de *timeout* y *rate‚Äëlimit*.  
**Entregables**: API funcional + imagen Docker + README.

---

## Mes 4 ‚Äî Deep Learning b√°sico

### Semana 1 ‚Äî Redes y entrenamiento
**Qu√© es**: MLP (capas densas), **backprop**, funciones de activaci√≥n (ReLU, GELU), p√©rdidas (MSE, CE), optimizadores (SGD, Adam).  
**Para qu√©**: aprender representaciones no lineales.  
**C√≥mo**: Keras: `Model.fit` con `callbacks` (EarlyStopping, ReduceLROnPlateau).  
**Pitfalls**: overfitting ‚Üí usa dropout/L2/early stopping.  
**Entregables**: MLP MNIST con >98% accuracy validaci√≥n.

### Semana 2 ‚Äî Regularizaci√≥n y *Augmentation*
**Qu√© es**: Dropout, L1/L2, BatchNorm; *augmentation* (ruido, flips).  
**Para qu√©**: generalizaci√≥n.  
**C√≥mo**: compara runs con/ sin regularizaci√≥n (MLflow).  
**Entregables**: informe comparativo + curvas loss/accuracy.

### Semana 3 ‚Äî PyTorch vs Keras
**Qu√© es**: dos *frameworks* l√≠deres.  
**Para qu√©**: elegir seg√∫n preferencia/ecosistema.  
**C√≥mo**: re‚Äëimplementa el mismo MLP en ambos.  
**Entregables**: dos scripts de entrenamiento equivalentes.

### Semana 4 ‚Äî *Experiment tracking*
**Qu√© es**: registrar hiperpar√°metros/artefactos (**MLflow**).  
**Para qu√©**: reproducibilidad, auditor√≠a.  
**C√≥mo**: `mlflow.sklearn.log_model`, `mlflow.log_params/metrics`.  
**Entregables**: 5+ ejecuciones registradas.

---

## Mes 5 ‚Äî Visi√≥n por Computadora (CNN)

### Semana 1 ‚Äî Convoluciones y *Transfer Learning*
**Qu√© es**: CNN (conv, stride, padding, pooling); **transfer learning** con ResNet/MobileNet.  
**Para qu√©**: clasificar/detectar con pocos datos.  
**C√≥mo**: congelar capas, re‚Äëentrenar *head*.  
**Pitfalls**: *overfitting* sin augmentation; LR muy alta.  
**Entregables**: clasificador con F1>0.9 en tu dataset.

### Semana 2 ‚Äî Proyecto visi√≥n
**Qu√© es**: caso aplicado (defectos de producto o clasificaci√≥n SKU).  
**Para qu√©**: calidad y automatizaci√≥n.  
**C√≥mo**: dataset balanceado, *stratified split* por clase.  
**Entregables**: modelo + informe de errores (top‚Äëconfusions).

### Semana 3 ‚Äî Exportaci√≥n
**Qu√© es**: **TensorFlow Lite** / **ONNX** / cuantizaci√≥n.  
**Para qu√©**: inferencia en m√≥vil/edge.  
**C√≥mo**: exporta y mide latencia/precisi√≥n.  
**Entregables**: archivo `.tflite`/`.onnx` + pruebas.

### Semana 4 ‚Äî App Android
**Qu√© es**: inferencia on‚Äëdevice (Kotlin).  
**Para qu√©**: experiencia offline, r√°pida y privada.  
**Entregables**: demo c√°mara ‚Üí predicci√≥n.

---

## üî¥ Meses 6‚Äì7 ‚Äî Predicci√≥n de Compras e Inventario (EN DETALLE)

### Mes 6 ‚Äî Forecast de demanda (Parte I)
**Qu√© es**: **series temporales** con nivel/tendencia/estacionalidad y ruido.  
**Para qu√©**: anticipar demanda por SKU para planificar compras/producci√≥n.  
**C√≥mo estudiarlo**:
1) **Re‚Äëmuestreo** a diario/semanal; completar ceros; *cut‚Äëover* por alta/baja de SKUs.  
2) Baselines: *na√Øve* (ma√±ana = hoy), *seasonal‚Äëna√Øve* (pr√≥x. lunes = lunes pasado).  
3) **ETS (Holt‚ÄëWinters)**: captura tendencia/estacionalidad aditiva/multiplicativa.  
4) **ARIMA/SARIMA/SARIMAX**: modela autocorrelaci√≥n; `SARIMAX(endog, exog=calendar/promos/precio)`.  
5) **Validaci√≥n temporal** (*walk‚Äëforward*): entrena en [t0,t1], predice [t1,t2]; desliza ventana.  
6) M√©tricas: **WAPE** (= Œ£|y‚àí≈∑| / Œ£y), **sMAPE**, **MASE** (robusta a escala).  
**Pitfalls**: mezclar datos de futuro; no separar por SKU; ignorar d√≠as cero v√°lidos.  
**Entregables**: *pipeline* por SKU con backtesting + tablero Vue (serie real vs predicci√≥n y error).  
**Recursos**: `statsmodels` (ETS/ARIMA), ‚ÄúForecasting: Principles and Practice‚Äù (Hyndman).

#### Tabla r√°pida de Z (nivel de servicio ‚Üí Z)
| Servicio | Z aproximado |
|---|---|
| 90% | 1.28 |
| 95% | 1.645 |
| 97.5% | 1.96 |
| 99% | 2.33 |

### Mes 7 ‚Äî De forecast a √≥rdenes de compra (Parte II)
**Qu√© es**: traducir demanda esperada a **cu√°ndo** y **cu√°nto** comprar.  
**Para qu√©**: minimizar roturas y capital inmovilizado.  
**C√≥mo estudiarlo**:
1) **Demanda intermitente** (muchos ceros): **Croston/SBA/TSB** (frecuencia √ó tama√±o).  
2) **Lead time**: media y desviaci√≥n por proveedor (usa `suppliers`); incluye festivos.  
3) **Safety Stock (SS)** y **ROP**:  
   - Fijo: `SS = Z * œÉ_d * sqrt(L)`; `ROP = Œº_d * L + SS`.  
   - Variable: `SS = Z * sqrt( Œº_L œÉ_d¬≤ + Œº_d¬≤ œÉ_L¬≤ )`.  
4) **Pol√≠ticas**: (Q,R) cantidad fija/pedido cuando stock < ROP; (s,S) revisar cada *s* d√≠as y llevar a *S*.  
5) **EOQ**: `sqrt(2 K D / h)`; ajusta por **MOQ** y **price breaks**.  
6) **Priorizaci√≥n ABC/XYZ**: A por valor, X por estabilidad ‚Üí nivel de servicio alto primero.  
**Pitfalls**: usar media global para todos; no considerar **on_order/backorders**; ignorar variabilidad del lead time.  
**Entregables**: microservicio ‚Äú**Purchase Recommender**‚Äù: endpoint `/purchase_suggestions?sku=...` con `next_order_date`, `qty`, `reason`.  
**Recursos**: libros de *Inventory Control*, notas de Silver/Zaik, material de Hyndman sobre intermitentes.

**Glosario compra/inventario**:  
- **WAPE/sMAPE/MASE**: errores relativos para comparar SKUs.  
- **Bullwhip effect**: variabilidad amplificada r√≠o arriba; mit√≠galo con ventanas y *smoothing*.  
- **Fill rate**: % de demanda atendida sin stockout.  
- **Coverage**: d√≠as de inventario disponibles.

---

## Mes 8 ‚Äî NLP cl√°sico

### Semana 1 ‚Äî Preprocesamiento
**Qu√© es**: normalizar (min√∫sculas), tokenizar, *stemming/lemmatizaci√≥n*.  
**Para qu√©**: preparar texto para modelos.  
**C√≥mo**: `nltk/spacy`; limpia HTML, emojis, stopwords (con cuidado).  
**Pitfalls**: eliminar negaciones (‚Äúno‚Äù); romper entidades.  
**Entregables**: script `src/nlp_clean.py`.

### Semana 2 ‚Äî Vectorizaci√≥n
**Qu√© es**: representar texto como n√∫meros. **TF‚ÄëIDF**, *n‚Äëgrams*, **Word2Vec/GloVe**.  
**Para qu√©**: alimentar clasificadores o regresores.  
**C√≥mo**: `TfidfVectorizer(ngram_range=(1,2))`; compara con embeddings preentrenados.  
**Entregables**: notebook comparativo.

### Semana 3 ‚Äî Clasificaci√≥n de texto
**Qu√© es**: intents/sentimientos.  
**C√≥mo**: LinearSVC/LogReg con TF‚ÄëIDF; eval√∫a con F1 macro.  
**Pitfalls**: *data leakage* al construir vocabulario.  
**Entregables**: modelo + reporte.

### Semana 4 ‚Äî API
**Entregables**: endpoint `/analyze` (Django/Laravel), tests y CI b√°sica.

---

## Mes 9 ‚Äî Transformers y RAG

### Semana 1 ‚Äî Transformers
**Qu√© es**: atenci√≥n, *positional encoding*, modelos **BERT/GPT**.  
**Para qu√©**: SOTA en NLP (QA, clasificaci√≥n, resumen).  
**C√≥mo**: `transformers` (Hugging Face): *tokenizer* ‚Üí modelo ‚Üí *pipeline*.  

### Semana 2 ‚Äî LoRA y Embeddings
**Qu√© es**: **LoRA** = *fine‚Äëtuning ligero*; **embeddings** = vectores sem√°nticos.  
**Para qu√©**: adaptar un LLM barato; b√∫squeda sem√°ntica.  
**C√≥mo**: *adapters* con PEFT; FAISS para indexar y buscar.  

### Semana 3 ‚Äî RAG
**Qu√© es**: **Retrieval‚ÄëAugmented Generation**.  
**Para qu√©**: respuestas con tus documentos privados.  
**C√≥mo**: *chunking* (512‚Äì1024 tokens), top‚Äëk, **re‚Äëranking**, *prompt templates*.  
**Pitfalls**: *chunking* muy grande; no manejar fuentes.  
**Entregables**: chatbot con citas a documentos.

### Semana 4 ‚Äî Producto
**Entregables**: servicio RAG (backend) + UI Vue con historial y feedback.

---

## Mes 10 ‚Äî Visi√≥n avanzada

### Semana 1 ‚Äî Detecci√≥n/Segmentaci√≥n
**Qu√© es**: **YOLO/Faster R‚ÄëCNN/Mask R‚ÄëCNN**; m√©tricas **IoU**/**mAP**.  
**Para qu√©**: localizar objetos, contar, segmentar.  
**C√≥mo**: anotar datos (Label Studio/Roboflow); *train* y evaluar.  
**Pitfalls**: *class imbalance*; *non‚Äëmax suppression* mal ajustado.  

### Semana 2 ‚Äî OCR
**Qu√© es**: **Tesseract** (+ preprocesado OpenCV); post‚Äëproceso con reglas/LLM.  
**Para qu√©**: digitalizar facturas/albaranes.  
**Entregables**: microservicio OCR con colas (RQ/Celery).

### Semana 3‚Äì4 ‚Äî Proyecto completo
**Entregables**: pipeline OCR + validaciones + dashboard operativo (errores por campo, tasa de correcci√≥n).

---

## Mes 11 ‚Äî IA generativa

### Semana 1 ‚Äî LLMs en producci√≥n
**Qu√© es**: consumo por API o modelos *open‚Äësource*.  
**Para qu√©**: asistentes, res√∫menes, extracci√≥n, *function calling*.  
**C√≥mo**: *prompting* (instrucciones, ejemplos, restricciones), *guardrails*.  

### Semana 2 ‚Äî Im√°genes
**Qu√© es**: **Stable Diffusion** (text‚Äëto‚Äëimage).  
**Para qu√©**: marketing, prototipos, variantes de im√°genes.  
**Pitfalls**: costes GPU; pol√≠tica de contenido.  

### Semana 3 ‚Äî Audio
**Qu√© es**: **Whisper** (STT), TTS.  
**Para qu√©**: dictado, bots de voz.  
**Entregables**: pipeline audio ‚Üí texto ‚Üí acci√≥n.

### Semana 4 ‚Äî App generativa
**Entregables**: app full‚Äëstack (Vue + backend) combinando texto/imagen/audio.

---

## Mes 12 ‚Äî MLOps y producci√≥n

### Semana 1 ‚Äî Versionado y datos
**Qu√© es**: **DVC/MLflow** para versiones de datos/modelos.  
**Para qu√©**: reproducibilidad.  
**Entregables**: *pipeline* con cach√© y artefactos.

### Semana 2 ‚Äî CI/CD y tests
**Qu√© es**: integraci√≥n y despliegue continuo; **Great Expectations** para tests de datos.  
**Para qu√©**: prevenir degradaciones.  
**Entregables**: workflow CI (lint/test/build/push).

### Semana 3 ‚Äî Observabilidad y *drift*
**Qu√© es**: **drift** de *features* (covariate) o de etiquetas (concept).  
**Para qu√©**: detectar cu√°ndo re‚Äëentrenar.  
**Entregables**: alertas + tablero m√©tricas en producci√≥n.

### Semana 4 ‚Äî *Runbook* y *SLA*
**Qu√© es**: manual de operaci√≥n y objetivos (latencia, error).  
**Entregables**: deploy cloud + *runbook* + post‚Äëmortem simulado.

---

## Ap√©ndice A ‚Äî API de Sugerencia de Compras (ejemplo)

**Endpoints**  
- `GET /health` ‚Üí ok.  
- `POST /forecast` ‚Üí body: `{ sku, horizon_days }` ‚Üí devuelve serie pronosticada.  
- `POST /purchase_suggestions` ‚Üí body: `{ sku, on_hand, on_order, backorders, lead_time_mean, lead_time_std, service_level, moq, budget }` ‚Üí `{ next_order_date, recommended_qty, reason, coverage_days }`.

**L√≥gica**  
1) Construye demanda diaria neta.  
2) Elige modelo (ETS/SARIMA/Croston) por CV.  
3) Calcula SS/ROP y **Q** (EOQ/heur√≠stica).  
4) Aplica reglas de presupuesto y **ABC/XYZ**.  
5) Devuelve explicaci√≥n de la recomendaci√≥n (**reason**).

---

## Ap√©ndice B ‚Äî Checklists √∫tiles

**Calidad de datos (antes de modelar)**  
- [ ] % de `missing` por columna < 10% (o imputado justificado)  
- [ ] Outliers explicados/recortados  
- [ ] Duplicados tratados  
- [ ] Consistencia de unidades y moneda  
- [ ] Alineaci√≥n de fechas y TZ

**Forecast**  
- [ ] *Walk‚Äëforward* implementado  
- [ ] Baselines comparados  
- [ ] Ex√≥genas (calendario/promo/precio) evaluadas  
- [ ] M√©trica negocio (**WAPE**, *fill‚Äërate*) incluida

**Inventario**  
- [ ] Lead time por proveedor (media y std)  
- [ ] Pol√≠ticas (Q,R) o (s,S) definidas por familia  
- [ ] Tabla de Z validada con negocio  
- [ ] Alertas por *stockout* y exceso

---

## Ap√©ndice C ‚Äî Glosario rel√°mpago (t√©rminos clave)

- **Data leakage**: usar informaci√≥n del futuro en entrenamiento; da m√©tricas irreales.  
- **ROC‚ÄëAUC / PR‚ÄëAUC**: calidad de ranking de probabilidades; PR‚ÄëAUC mejor con clases desbalanceadas.  
- **PCA**: combinaci√≥n lineal ortogonal que maximiza varianza; √∫til para visualizaci√≥n/compresi√≥n.  
- **MLflow**: seguimiento de experimentos y modelos.  
- **ETS/ARIMA/SARIMA/SARIMAX**: familias de modelos de series (tendencia/estacionalidad/ex√≥genas).  
- **Croston/SBA/TSB**: m√©todos para demanda intermitente (estimaci√≥n de intervalo y tama√±o).  
- **EOQ**: calcula lote econ√≥mico balanceando coste de pedido y de inventario.  
- **ABC/XYZ**: priorizaci√≥n por valor (ABC) y variabilidad (XYZ).  
- **FAISS**: √≠ndice para b√∫squeda de vectores (embeddings).  
- **RAG**: recuperaci√≥n + generaci√≥n, para respuestas basadas en documentos.  
- **Drift**: cambio en la distribuci√≥n (covariate) o en la relaci√≥n X‚Üíy (concept).  
- **Great Expectations**: framework de tests de datos.  
- **ONNX/TFLite**: formatos/entornos para ejecutar modelos portables y ligeros.

---

## Ap√©ndice D ‚Äî Recursos de estudio (curado, breve)

- **Libros**: 
  - ‚ÄúHands‚ÄëOn Machine Learning‚Äù (G√©ron) ‚Äî ML/DL pr√°ctico.  
  - ‚ÄúForecasting: Principles and Practice‚Äù (Hyndman & Athanasopoulos) ‚Äî forecasting aplicado.  
  - ‚ÄúDeep Learning‚Äù (Goodfellow et al.) ‚Äî fundamentos te√≥ricos.

- **Docs oficiales**: scikit‚Äëlearn, pandas, statsmodels, PyTorch, TensorFlow, MLflow, FastAPI, Hugging Face.

- **Cursos**: 
  - Machine Learning (Andrew Ng) ‚Äî fundamentos.  
  - NLP with Transformers (HF) ‚Äî pr√°ctico.  
  - MLOps b√°sicos (varios proveedores).

- **Herramientas**: Label Studio (anotaci√≥n), DVC/MLflow (versionado/seguimiento), Great Expectations (calidad), Airflow (orquestaci√≥n).

---

## Siguientes pasos inmediatos
1) Elige un dataset propio del negocio y ejecuta **Mes 1‚Äì2** con EDA + 1¬∫ modelo.  
2) Prepara **series por SKU** y aplica **Mes 6** (ETS/SARIMA, backtesting).  
3) Implementa **Mes 7** para convertir pron√≥sticos en **√≥rdenes** (API + dashboard).  
4) Documenta decisiones y resultados en el README del proyecto.

