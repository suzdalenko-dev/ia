# ğŸ“š Calendario IA 12 Meses + PredicciÃ³n de Compras â€” **README.md**

> Plan paso a paso para convertirte en profesional de IA aplicando tu stack fullâ€‘stack (**HTML/JS/PHP/Java/Python/Kotlin/Android/SQL/SQLite/Laravel/Symfony/Django/Vue**).  
> Resultado: **10+ proyectos** en portafolio, **APIs listas para producciÃ³n** y un **motor de compras** (forecast â†’ cantidad a pedir) con mÃ©tricas de negocio.

---

## ğŸ§­ CÃ³mo usar este plan

- **Estructura por tema**: *QuÃ© es â†’ Para quÃ© sirve â†’ CÃ³mo estudiarlo â†’ Pitfalls â†’ Entregables â†’ Recursos â†’ CÃ³mo lo usarÃ¡s en proyectos*.
- **Tiempo**: 6â€“10 h/semana. Cada semana tiene objetivos concretos.
- **Repositorio base** (recomendado):
  ```text
  project/
    data/            # raw/processed/interim/external
    notebooks/
    src/
    models/
    api/
    reports/
    docker/
    .env.example
    requirements.txt / pyproject.toml
    Makefile
  ```
- **Workflow**: (1) Leer, (2) Reproducir, (3) Reâ€‘implementar sin mirar, (4) Aplicar a tus datos, (5) Documentar.

---

# A) Ãlgebra, CÃ¡lculo y Probabilidad â€œmÃ­nimasâ€ para IA (Semana 1.5)

> Inserta esta **Semana 1.5** entre tus Semanas 1 y 2. Ãšsala tambiÃ©n como **ficha de consulta** todo el aÃ±o.

## 1) Ãlgebra lineal esencial

**QuÃ© es**  
- Espacios vectoriales y **normas**: \(\ell_1,\ \ell_2,\ \ell_\infty\); normalizaciÃ³n/escalado.  
- **Producto escalar** y **proyecciones** (descomposiciÃ³n ortogonal). ProyecciÃ³n: \(P = X(X^\top X)^{-1} X^\top\).  
- **Matrices**: rango, traza, determinante, inversa, simÃ©tricas, **PSD** (\(x^\top A x \ge 0\)).  
- **Autovalores/autovectores**: estabilidad numÃ©rica, condicionamiento.  
- **SVD**: \(X = U\,\Sigma\,V^\top\) â†’ reducciÃ³n de dimensiÃ³n, compresiÃ³n, **PCA**.  
- **PCA**: varianza explicada, *whitening*.

**Para quÃ© sirve**  
- Entender la **geometrÃ­a de los datos**, compresiÃ³n/ruido, reducciÃ³n de dimensiÃ³n y **descorrelaciÃ³n**.
- Fundamental para **recomendadores**, **visiÃ³n** (bases ortogonales), **clustering** y **explicabilidad**.

**CÃ³mo estudiarlo**  
- Implementa **PCA** con **SVD** desde cero y compÃ¡ralo con `sklearn`.  
- Juega con **escalado** (zâ€‘score, minâ€‘max) y mide el impacto en kâ€‘means/svm.

**Pitfalls**  
- Invertir matrices â€œa peloâ€. Preferir **Cholesky/QR/SVD**.  
- Aplicar PCA sin estandarizar *features* que estÃ¡n en escalas distintas.

**Entregables**  
- **Cheatâ€‘sheet** A4 con identidades (proyecciÃ³n, traza, derivadas).  
- Notebook de **PCA por SVD** + *plot* de varianza explicada.

**Recursos rÃ¡pidos**  
- â€œLinear Algebra Reviewâ€ (CS229).  
- â€œMatrix Cookbookâ€ (identidades y derivadas).

**CÃ³mo lo usarÃ¡s en proyectos**  
- **Mes 2â€“4**: PCA para visualizaciÃ³n 2D de clientes (segmentaciÃ³n).  
- **Mes 9 (RAG)**: reducciÃ³n de dimensiÃ³n para *debug* de **embeddings**.  
- **Mes 10 (visiÃ³n)**: comprensiÃ³n de **timm/Conv** y compresiÃ³n con SVD/ONNX.

---

## 2) CÃ¡lculo (vectorial y matricial)

**QuÃ© es**  
- **Gradiente**, **Jacobiano**, **Hessiano**; **regla de la cadena**.  
- **CÃ¡lculo matricial** Ãºtil:
  - \(\frac{\partial}{\partial X}\,\mathrm{tr}(AX) = A^\top\)  
  - \(\frac{\partial}{\partial X}\,\lVert AX-b\rVert_2^2 = 2A^\top(AX-b)\)  
  - \(\frac{\partial}{\partial X}\,\log\det X = (X^{-1})^\top\) (X simÃ©trica PD).

**Para quÃ© sirve**  
- Entender **backprop**, **regularizaciÃ³n** y **optimizaciÃ³n** de pÃ©rdidas (por quÃ© funciona Adam, por quÃ© *early stopping* regulariza).

**CÃ³mo estudiarlo**  
- Deriva la **MSE** y la **logÃ­stica**.  
- Calcula a mano un paso de **descenso de gradiente** en regresiÃ³n.

**Entregables**  
- Notebook con derivadas y comparaciÃ³n con *autograd* (PyTorch).

**Recurso claro**  
- â€œThe Matrix Calculus You Need for Deep Learningâ€.

**CÃ³mo lo usarÃ¡s en proyectos**  
- Ajustar **LR/weight decay** con criterio y diagnosticar **overfitting** vs **underfitting**.  
- Implementar pÃ©rdidas custom (ej. **WAPE/SMAPE** para **forecast**).

---

## 3) OptimizaciÃ³n

**QuÃ© es**  
- **Convexidad** (Jensen), **Lipschitz**, **condicionamiento**.  
- **GD/Momentum/Adam**; **early stopping** y **regularizaciÃ³n** (L1/L2).  
- **Lagrangiano** y **multiplicadores** (intuiciÃ³n prÃ¡ctica).

**Para quÃ© sirve**  
- Convergencia **mÃ¡s estable** y modelos que **generalizan** mejor.  
- DiseÃ±ar *schedules* de LR y *weight decay* adecuados a tu problema.

**CÃ³mo estudiarlo**  
- Comparativa de **SGD vs Adam** en el mismo MLP (curvas *loss/val*).

**Entregables**  
- Experimentos registrados en **MLflow**, con tabla de *runs* y mÃ©tricas.

**CÃ³mo lo usarÃ¡s en proyectos**  
- **Mes 4â€“5**: entrenos de **transfer learning** estables.  
- **Mes 6â€“7**: *tuning* de ETS/ARIMA con *grid/random* bien acotado.

---

## 4) Probabilidad y estadÃ­stica

**QuÃ© es**  
- Distribuciones: **Bernoulli, Binomial, Poisson, Exponencial, Normal**.  
- Momentos: \(\mathbb E[X]\), **Var/Cov**, matrices de covarianza.  
- **MLE/MAP**, intervalos de confianza, **bootstrap**.  
- **EntropÃ­a**, **crossâ€‘entropy**, **KL** (clasificaciÃ³n y VAEs).  
- Series: **autocovarianza**, **ACF/PACF** (para **Mes 6**).

**Para quÃ© sirve**  
- Elegir **mÃ©tricas** y **intervalos** realistas; entender **riesgo** y **incertidumbre** en predicciÃ³n de demanda.

**Pitfalls**  
- Confundir varianza poblacional vs muestral.  
- Mezclar escalas/unidades sin normalizar.

**Entregables**  
- Notebook: estimaciÃ³n de \(\mu\) y \(\sigma\) con **bootstrap** + bandas de confianza.

**CÃ³mo lo usarÃ¡s en proyectos**  
- **Mes 7**: stock de seguridad (\(SS\)) y punto de pedido (\(ROP\)) con **Zâ€‘scores**.  
- **Mes 3**: *threshold tuning* de clasificadores con curvas **PR** y coste.

---

## 5) Entregables rÃ¡pidos (resumen)

- **Hoja de fÃ³rmulas** (A4) con 25 identidades (traza, logâ€‘det, proyecciones).  
- Notebook de ejercicios:
  1. Deriva **MSE** y **logÃ­stica**.
  2. Implementa **PCA por SVD** y compÃ¡ralo con `sklearn`.
  3. Estima \(\sigma\) y \(\mu\) con **bootstrap** y grafica intervalos.

---

# B) Ecosistema de bibliotecas 2025 (curado y explicado)

> Para cada bloque: **Para quÃ© sirve** y **CÃ³mo lo usarÃ¡s** (conectado a tu plan).

## NÃºcleo de ciencia de datos

- **NumPy / pandas** â€” estÃ¡ndar de arrays y DataFrames.  
  **UsarÃ¡s**: EDA, *feature engineering*, *pipelines* tabulares.
- **Polars** â€” DataFrames **muy rÃ¡pidos** (nÃºcleo en Rust, *lazy*).  
  **UsarÃ¡s**: ETL y analÃ­tica a gran escala en 1 mÃ¡quina (suele reemplazar pandas cuando el dataset crece).
- **DuckDB** â€” OLAP **inâ€‘process** (SQL), Parquet/CSV/S3.  
  **UsarÃ¡s**: *joins* y agregaciones masivas desde notebooks o scripts, complementando pandas/Polars.

## ML clÃ¡sico

- **scikitâ€‘learn** â€” *pipelines*, mÃ©tricas, validaciÃ³n, *model selection*.  
  **UsarÃ¡s**: base de regresiÃ³n/clasificaciÃ³n/clustering + **TimeSeriesSplit**.
- **XGBoost / LightGBM / CatBoost** â€” *boosting* SOTA en tabular.  
  **UsarÃ¡s**: tabular serio (churn, fraude). CatBoost para categÃ³ricas pesadas.

## Deep Learning

- **PyTorch 2.x** â€” DL flexible (eager) y ecosistema enorme.  
  **UsarÃ¡s**: MLP/CNN/Transformers, *transfer learning* y pÃ©rdidas custom.  
- **TensorFlow/Keras** â€” API alto nivel + **TFLite** en mÃ³vil/edge.  
  **UsarÃ¡s**: exportar a **Android** (onâ€‘device).  
- **JAX** (opcional) â€” *jit/vmap/pmap* para investigaciÃ³n numÃ©rica.  
- **timm / torchmetrics / Lightning** â€” *model zoo*, mÃ©tricas, orquestaciÃ³n de *training*.  
- **MLflow** â€” *experiment tracking* y **model registry** (estÃ¡ndar de facto).

## VisiÃ³n por Computadora

- **OpenCV** â€” preprocesado y utilidades de imagen/video.  
- **Albumentations** â€” *augmentation* rÃ¡pido y flexible.  
- **Ultralytics YOLO** â€” detecciÃ³n/segmentaciÃ³n/pose con *training* sencillo.

## NLP / LLM

- **Hugging Face (Transformers/Datasets/Tokenizers)** â€” *pipelines* y *model zoo*.  
  **UsarÃ¡s**: *fineâ€‘tuning* ligero (LoRA), inferencia y **embeddings**.  
- **spaCy** â€” NLP productivo (tokenizaciÃ³n/NER).  
- **SentencePiece/Tokenizers** â€” *subword* para vocabularios personalizados.
- **Servidores LLM**: **vLLM** (alto throughput), **TGI** (server listo), **llama.cpp/Ollama** (local).  
  **UsarÃ¡s**: servir modelos en **RAG** y prototipos locales.

## RAG / BÃºsqueda vectorial

- **FAISS** / **pgvector** / **Qdrant/Weaviate/Milvus** â€” Ã­ndices y DBs vectoriales.  
  **UsarÃ¡s**: bÃºsqueda semÃ¡ntica en RAG y recomendadores hÃ­bridos.  
- **LangChain / LlamaIndex** â€” *chains*, *retrievers*, *reâ€‘ranking*.  
  **UsarÃ¡s**: orquestar RAG con herramientas y *guardrails*.

## EvaluaciÃ³n, calidad y observabilidad

- **Evidently** â€” *drift/monitoring*.  
- **Great Expectations** â€” **tests de datos** (calidad).  
- **Ragas / DeepEval / LMâ€‘Evalâ€‘Harness** â€” evaluaciÃ³n de RAG/LLM.  
- **Langfuse** â€” **trazas** y analÃ­tica para LLM apps.

## Serving e Inferencia

- **FastAPI + Pydantic v2** â€” APIs rÃ¡pidas y tipadas.  
- **ONNX Runtime / NVIDIA Triton / BentoML / Ray Serve / KServe** â€” inferencia en CPU/GPU/K8s.  
  **UsarÃ¡s**: exportar modelos a **ONNX** (portabilidad) y servir en CPU/GPU.

## OrquestaciÃ³n / MLOps

- **DVC** â€” versionado de datos.  
- **MLflow** â€” experimentos y **model registry**.  
- **Airflow / Prefect / Dagster** â€” *pipelines* y scheduling (Prefect = DX muy limpia).

## Web y MÃ³vil (onâ€‘device)

- **Transformers.js / ONNX Runtime Web / TensorFlow.js** â€” inferencia en navegador (WebGPU/WASM).  
- **TFLite/LiteRT / ML Kit / ONNX Runtime Mobile** â€” inferencia en Android/iOS.  
  **UsarÃ¡s**: PoCs *serverless* y apps mÃ³viles privadas/offline.

---

# Stacks de referencia y **cÃ³mo los usarÃ¡s**

### 1) Tabular (regresiÃ³n/clasificaciÃ³n)
**Stack**: pandas/Polars â†’ scikitâ€‘learn + (XGBoost/LightGBM) â†’ MLflow â†’ FastAPI/ONNX Runtime â†’ Airflow/Prefect.  
**Por quÃ©**: mÃ¡xima eficacia en datos empresariales (tabulares).  
**CÃ³mo lo usarÃ¡s**: **churn, fraude, scoring** con API `/predict`, dashboard Vue y *monitoring* con Evidently.

### 2) Forecast por SKU (Mes 6â€“7)
**Stack**: pandas/Polars â†’ statsmodels (ETS/SARIMA) + baselines â†’ backtesting (*walkâ€‘forward*) â†’ FastAPI + Vue â†’ MLflow/Evidently.  
**CÃ³mo lo usarÃ¡s**: **motor de compras** â†’ `SS/ROP/EOQ`, priorizaciÃ³n **ABC/XYZ**, endpoint `/purchase_suggestions`.

### 3) NLP clÃ¡sico (spam/intents)
**Stack**: spaCy/NLTK â†’ TFâ€‘IDF + LinearSVC/LogReg (o DistilBERT) â†’ FastAPI.  
**CÃ³mo lo usarÃ¡s**: filtros de **spam** y **intents** en soporte/tickets.

### 4) RAG de documentaciÃ³n interna
**Stack**: ingestiÃ³n/chunking â†’ embeddings (HF/SBERT) â†’ FAISS/pgvector â†’ LangChain/LlamaIndex â†’ vLLM/TGI â†’ Ragas/Langfuse.  
**CÃ³mo lo usarÃ¡s**: **asistente** de conocimiento con **citas** y **evaluaciÃ³n** continua.

### 5) VisiÃ³n (defectos/SKU)
**Stack**: OpenCV + Albumentations â†’ PyTorch/timm o YOLO â†’ ONNX/TFLite â†’ Triton/Android.  
**CÃ³mo lo usarÃ¡s**: control de **calidad** y conteo/clasificaciÃ³n rÃ¡pida en mÃ³vil.

### 6) Inâ€‘browser
**Stack**: Transformers.js u ONNX Runtime Web.  
**CÃ³mo lo usarÃ¡s**: demo sin backend (privacidad, cero latencia de red).

### 7) Android onâ€‘device
**Stack**: TFLite/ML Kit/ONNX Runtime Mobile.  
**CÃ³mo lo usarÃ¡s**: **apps offline** (visiÃ³n/NLP) integradas con tu stack Kotlin.

---

# Consejos prÃ¡cticos (de profesional a profesional)

- **Elige DataFrame**: si haces ETL/analÃ­tica pesada en 1 mÃ¡quina, **Polars + DuckDB** = combo rÃ¡pido y barato.  
- **Sirve LLMs sin dolor**: empieza por **vLLM** (prod) u **Ollama** (local/dev). **TGI** si prefieres server listo.  
- **EvalÃºa RAG desde el dÃ­a 1**: integra **Ragas** en CI y traza con **Langfuse**.  
- **Observabilidad**: *drift* con **Evidently**; **Great Expectations** para *data tests*; reâ€‘entrenos **gated** por mÃ©tricas de negocio.  
- **Exportabilidad**: compila a **ONNX** temprano â†’ abre **Triton**, **ORT Web/Mobile**, **KServe**.

---

# QuÃ© aÃ±adir al calendario (puntos concretos)

- **Mes 1 â€” Semana 1.5 (nuevo)**: repaso de Ã¡lgebra/cÃ¡lculo (arriba) + 2â€“3 *katas*/dÃ­a.  
  **Entregables**: *cheatâ€‘sheet* A4 + notebook de derivadas/PCA + miniâ€‘quiz.
- **Mes 3 â€” Feature Store (1 dÃ­a)**: mira **Feast** si compartirÃ¡s *features* entre equipos.  
- **Mes 4 â€” Tracking serio**: estandariza **MLflow** (experimentos + *model registry*; tags: dataset, git sha, semilla).  
- **Mes 9 â€” RAG**: aÃ±ade **Ragas** y *prompt hardening*.  
- **Mes 12 â€” Serving**: ensaya **Triton** (GPU) y **ONNX Runtime** (CPU/Edge) + *smoke tests* en CI.

---

# Miniâ€‘glosario extra

- **SVD vs Eig**: SVD funciona para cualquier matriz; Eig solo en cuadradas.  
- **Lipschitz**: cota al cambio; te guÃ­a en *step size*.  
- **MAP**: MLE con *prior* â†’ L2 â‰ˆ **prior Gaussiano**, L1 â‰ˆ **Laplace**.  
- **vLLM**: servidor LLM con *PagedAttention* (alto *throughput*).  
- **TGI**: servidor de generaciÃ³n (Hugging Face) listo para prod.

---

# Siguientes pasos inmediatos

1. Imprime tu **cheatâ€‘sheet** y crea el **notebook** de derivadas + PCA.  
2. Elige **Polars + DuckDB** o **pandas** para tu EDA base y registra todo con **MLflow**.  
3. Para **RAG**: prueba **FAISS + LangChain + vLLM** con un PDF del negocio y mide con **Ragas**.

---

## CrÃ©ditos y recursos (rÃ¡pidos)

- Libros: *Handsâ€‘On Machine Learning* (GÃ©ron), *Forecasting: Principles and Practice* (Hyndman), *Deep Learning* (Goodfellow).  
- Docs oficiales: scikitâ€‘learn, pandas/Polars, statsmodels, PyTorch, TensorFlow, MLflow, FastAPI, Hugging Face, DuckDB.  
- Herramientas: Label Studio, DVC/MLflow, Great Expectations, Airflow/Prefect, Evidently, Langfuse.

---

> **Pro tip**: este README es tu â€œcontratoâ€ de aprendizaje. Cada semana **marca entregables**, sube *screenshots* a `reports/` y escribe un **postâ€‘mortem** corto con lo aprendido y quÃ© harÃ¡s distinto la prÃ³xima vez.
